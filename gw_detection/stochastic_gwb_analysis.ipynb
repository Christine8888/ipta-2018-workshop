{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using enterprise to analyze PTA data\n",
    "### Developed by Steve Taylor, Subverted by Jeff Hazboun\n",
    "\n",
    "Based on original worksheets in the IPTA GitHub [page](https:/github.com/ipta/gwa_tutorials).\n",
    "\n",
    "In this notebook you will learn:\n",
    "* How to use `enterprise` to interact with IPTA data,\n",
    "* How to search in PTA data for GWs,\n",
    "* How to post-process your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:39.150382Z",
     "start_time": "2018-05-15T21:48:39.094542Z"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os, glob, json \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as sl\n",
    "\n",
    "import enterprise\n",
    "from enterprise.pulsar import Pulsar\n",
    "import enterprise.signals.parameter as parameter\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals import deterministic_signals\n",
    "import enterprise.constants as const\n",
    "\n",
    "import corner\n",
    "from PTMCMCSampler.PTMCMCSampler import PTSampler as ptmcmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a list of pulsar names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:40.498208Z",
     "start_time": "2018-05-15T21:48:40.378625Z"
    }
   },
   "outputs": [],
   "source": [
    "# The pulsars we'll be analyzing\n",
    "psrlist = np.load('./psr_names.npy')\n",
    "psrlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get par, tim, and noise files\n",
    "Here we collect the tim and par files as well as noise files made from the `PAL2` code. These are the same par, tim, and noise files used in the 9-year analysis papers. We use the convienience function above to convert from `PAL2` noise files to `enterprise` parameter dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:42.658570Z",
     "start_time": "2018-05-15T21:48:42.631742Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = './dataset1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:43.043752Z",
     "start_time": "2018-05-15T21:48:43.007076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parfiles = sorted(glob.glob(datadir + '/*.par'))\n",
    "timfiles = sorted(glob.glob(datadir + '/*.tim'))\n",
    "\n",
    "# filter\n",
    "parfiles = [x.encode('ascii') for x in parfiles if x.split('/')[-1].split('.')[0] in psrlist]\n",
    "timfiles = [x.encode('ascii') for x in timfiles if x.split('/')[-1].split('.')[0] in psrlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:48:43.452613Z",
     "start_time": "2018-05-15T21:48:43.421953Z"
    }
   },
   "outputs": [],
   "source": [
    "len(parfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into Pulsar class list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `enterprise` Pulsar class uses `libstempo` to read in `par` and `tim` files, then stores all pulsar data into a `Pulsar` object. This object contains all data and meta-data needed for the ensuing pulsar and PTA analysis. You no longer to reference the `par` and `tim` files after this cell.\n",
    "* Note below that you can explicitly declare which version of the JPL solar-system ephemeris model that will be used to compute the Roemer delay between the geocenter and the barycenter (e.g. `DE436`). Otherwise the default values will be taken from the `par` files. Explicitly declaring the version here is good practice.\n",
    "* You can also explicitly set the clock file to a version of `BIPM`, e.g. `BIPM(2015)`. This is less important, and you can let the code take the value from the `par` file.\n",
    "* When you execute the following cell, you will get warnings like `WARNING: Could not find pulsar distance for PSR ...`. Don't worry! This is expected, and fine. Not all pulsars have well constrained distances, and will be set to `1 kpc` with a `20%` uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:00.790991Z",
     "start_time": "2018-05-15T21:48:53.703630Z"
    }
   },
   "outputs": [],
   "source": [
    "psrs = []\n",
    "for p, t in zip(parfiles, timfiles):\n",
    "    psr = Pulsar(p, t, ephem='DE436', clk=None)\n",
    "    psrs.append(psr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTA Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can read-in some previously computed noise properties from single-pulsar analyses. These are things like `EFAC`, `EQUAD`, and (for `NANOGrav`) `ECORR`. \n",
    "* In practice, we set these white-noise properties as fixed in the low-frequency noise / GW searches.\n",
    "* The noise properties have been stored as `json` files, and are read in to a big parameter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:00.827936Z",
     "start_time": "2018-05-15T21:49:00.793658Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisefiles = sorted(glob.glob('./dataset1/noise/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:00.874553Z",
     "start_time": "2018-05-15T21:49:00.830786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "for nf in noisefiles:\n",
    "    with open(nf, 'r') as fin:\n",
    "        params.update(json.load(fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up `enterprise` model for PTA upper-limit (*verbose version*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usually, in a full PTA analysis we fix all of the white noise (EFAC, EQUAD, and ECORR) parameters to the values obtained from the noise files. This is done by using `Constant` parameters. In this case we do not specify a default value for all instances of that parameter but instead will set them, based on their initialized pulsar and backend specific name, later via the `set_default_params` method of `PTA`. \n",
    "\n",
    "* We use the `Selection` object to define which noise parameters are assigned to which chunks of TOAs. This selection is based on unique combination of backends and receivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T16:39:50.133639Z",
     "start_time": "2018-05-11T16:39:50.102972Z"
    }
   },
   "source": [
    "* Another feature to notice is that **for upper limits** we do not use a uniform prior on the log of the red-noise or GWB amplitude. Instead we use a `LinearExp` prior (short for linear-exponent prior), that is a prior of the form $p(x)\\propto 10^x$. This is how we can still use the log of the parameter to sample but place a uniform prior on the parameter itself. We do this for both the red noise and GWB amplitude parameters. **For detection analyses** we still use a `Uniform` prior on the log of the red-noise and GWB amplitude. \n",
    "\n",
    "* In order to save on computing time we do not include spatial correlations here. Instead we model the GWB as a common red process across all pulsars. In `enterprise` we can do this with a simple trick. We pre-initialize the parameters before passing them to the `Signal` model. In this way the *same* parameter instance is used for all pulsars. Lastly, we fixt the spectral index of the GWB to be 13/3 (4.33) using the `Constant` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:45.238037Z",
     "start_time": "2018-05-15T21:49:45.209705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the maximum time span to set GW frequency sampling\n",
    "tmin = [p.toas.min() for p in psrs]\n",
    "tmax = [p.toas.max() for p in psrs]\n",
    "Tspan = np.max(tmax) - np.min(tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:48.496954Z",
     "start_time": "2018-05-15T21:49:48.470085Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define selection by observing backend\n",
    "selection = selections.Selection(selections.by_backend)\n",
    "\n",
    "# special selection for ECORR only use wideband NANOGrav data\n",
    "selection2 = selections.Selection(selections.nanograv_backends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:50.042751Z",
     "start_time": "2018-05-15T21:49:50.005677Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# white noise parameters\n",
    "# since we are fixing these to values from the noise file we set\n",
    "# them as constant parameters\n",
    "efac = parameter.Constant()\n",
    "equad = parameter.Constant()\n",
    "ecorr = parameter.Constant()\n",
    "\n",
    "# red noise parameters\n",
    "log10_A = parameter.LinearExp(-20, -11)\n",
    "gamma = parameter.Uniform(0, 7)\n",
    "\n",
    "# dm-variation parameters\n",
    "log10_A_dm = parameter.LinearExp(-20, -11)\n",
    "gamma_dm = parameter.Uniform(0, 7)\n",
    "\n",
    "# GW parameters (initialize with names here to use parameters in common across pulsars)\n",
    "log10_A_gw = parameter.LinearExp(-18,-12)('log10_A_gw')\n",
    "gamma_gw = parameter.Constant(4.33)('gamma_gw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T16:44:44.713491Z",
     "start_time": "2018-05-11T16:44:44.685587Z"
    }
   },
   "source": [
    "### Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:51.557605Z",
     "start_time": "2018-05-15T21:49:51.499006Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# white noise\n",
    "ef = white_signals.MeasurementNoise(efac=efac, selection=selection)\n",
    "eq = white_signals.EquadNoise(log10_equad=equad, selection=selection)\n",
    "ec = white_signals.EcorrKernelNoise(log10_ecorr=ecorr, selection=selection2)\n",
    "\n",
    "# red noise (powerlaw with 30 frequencies)\n",
    "pl = utils.powerlaw(log10_A=log10_A, gamma=gamma)\n",
    "rn = gp_signals.FourierBasisGP(spectrum=pl, components=30, Tspan=Tspan)\n",
    "\n",
    "# DM-variations (powerlaw with 30 frequencies)\n",
    "dm_basis = utils.createfourierdesignmatrix_dm(nmodes=30, Tspan=Tspan)\n",
    "dm_pl = utils.powerlaw(log10_A=log10_A_dm, gamma=gamma_dm)\n",
    "dm_gp = gp_signals.BasisGP(dm_pl, dm_basis, name='dm_gp')\n",
    "\n",
    "# gwb (no spatial correlations)\n",
    "cpl = utils.powerlaw(log10_A=log10_A_gw, gamma=gamma_gw)\n",
    "gw = gp_signals.FourierBasisGP(spectrum=cpl, components=30, Tspan=Tspan, name='gw')\n",
    "\n",
    "# for spatial correltions you can do...\n",
    "#orf = utils.hd_orf()\n",
    "#crn = gp_signals.FourierBasisCommonGP(cpl, orf, components=30, Tspan=Tspan, name='gw')\n",
    "\n",
    "# to add solar system ephemeris modeling...\n",
    "#eph = deterministic_signals.PhysicalEphemerisSignal(use_epoch_toas=True)\n",
    "\n",
    "# timing model\n",
    "tm = gp_signals.TimingModel(use_svd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:52.662732Z",
     "start_time": "2018-05-15T21:49:52.638142Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full model\n",
    "s = eq + rn + dm_gp + tm + gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:55.063952Z",
     "start_time": "2018-05-15T21:49:53.602147Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intialize PTA, adding ecorr only for NANOGrav pulsars\n",
    "models = []\n",
    "        \n",
    "for p in psrs:    \n",
    "    models.append(s(p))\n",
    "    \n",
    "pta = signal_base.PTA(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:49:56.940424Z",
     "start_time": "2018-05-15T21:49:56.910938Z"
    }
   },
   "outputs": [],
   "source": [
    "pta.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set white noise parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:50:00.319108Z",
     "start_time": "2018-05-15T21:50:00.244934Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pta.set_default_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters drawn from prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:50:03.822379Z",
     "start_time": "2018-05-15T21:50:03.788843Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "ndim = len(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:50:06.902347Z",
     "start_time": "2018-05-15T21:50:06.866018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial jump covariance matrix\n",
    "cov = np.diag(np.ones(ndim) * 0.01**2)\n",
    "\n",
    "sampler = ptmcmc(ndim, pta.get_lnlikelihood, pta.get_lnprior, cov, \n",
    "                 outDir='./chains/dataset1_crn/', resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:39.157421Z",
     "start_time": "2018-05-15T21:50:07.962002Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampler for N steps\n",
    "N = int(1e6)\n",
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:44.119807Z",
     "start_time": "2018-05-15T21:51:44.060350Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chain = np.loadtxt('./chains/dataset1_crn/chain_1.txt')\n",
    "burn = int(0.25 * chain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chain[:,-5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:46.102261Z",
     "start_time": "2018-05-15T21:51:45.927388Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(chain[burn:,-5], 50, normed=True, histtype='step', lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Upper limit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T21:51:49.718217Z",
     "start_time": "2018-05-15T21:51:49.682886Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upper = 10**np.percentile(chain[burn:, -5], q=95)\n",
    "print(upper)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "743px",
    "left": "0px",
    "right": "1458px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
